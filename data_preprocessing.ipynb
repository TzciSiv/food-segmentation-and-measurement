{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454450bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Masks now use 0=background, 1=food.\n"
     ]
    }
   ],
   "source": [
    "# We will:\n",
    "# 1. Download the FoodSeg103 dataset from Hugging Face.\n",
    "# 2. Go through each image and its segmentation label (mask).\n",
    "# 3. Save:\n",
    "#    - The original image as a JPG.\n",
    "#    - A *binary* mask as a PNG (0 = background, 1 = any kind of food).\n",
    "# https://xiongweiwu.github.io/foodseg103.html\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "ds = load_dataset(\"EduardoPacheco/FoodSeg103\")\n",
    "out_root = \"foodseg103_export\"\n",
    "\n",
    "for split in [\"train\", \"validation\"]:\n",
    "    img_dir = f\"{out_root}/{split}/images\"\n",
    "    mask_dir = f\"{out_root}/{split}/masks\"\n",
    "\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    os.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "    for i, row in enumerate(ds[split]):\n",
    "        img = row[\"image\"]\n",
    "        mask = row[\"label\"]\n",
    "\n",
    "        img_path = os.path.join(img_dir, f\"{i:05d}.jpg\")\n",
    "        img.save(img_path)\n",
    "\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        bin_mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "        bin_mask[mask > 0] = 1\n",
    "        bin_mask_img = Image.fromarray(bin_mask)\n",
    "\n",
    "        mask_path = os.path.join(mask_dir, f\"{i:05d}.png\")\n",
    "        bin_mask_img.save(mask_path)\n",
    "\n",
    "print(\"Done! Masks now use 0=background, 1=food.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e10c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Saved 831 single-card samples into 'single_card_52/images' and 'single_card_52/masks'.\n"
     ]
    }
   ],
   "source": [
    "# We want to:\n",
    "#   - Keep ONLY the samples where there is exactly ONE card in the mask (one card class present).\n",
    "# https://www.kaggle.com/datasets/luanademi/playing-card-ensemble-segmentation-masks?utm_source=chatgpt.com\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "PCK_PATH = r\"C:\\Users\\siuts\\Downloads\\asm\\CS489\\project\\scenes.pck\"   # change if needed\n",
    "OUT_ROOT = \"single_card_52\"\n",
    "IMG_DIR  = os.path.join(OUT_ROOT, \"images\")\n",
    "MASK_DIR = os.path.join(OUT_ROOT, \"masks\")\n",
    "\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "os.makedirs(MASK_DIR, exist_ok=True)\n",
    "\n",
    "# 3. Load pickle\n",
    "with open(PCK_PATH, \"rb\") as f:\n",
    "    obj = pickle.load(f)\n",
    "\n",
    "images = obj[\"data\"]\n",
    "masks  = obj[\"gt\"]\n",
    "\n",
    "n_img  = len(images)\n",
    "n_mask = len(masks)\n",
    "\n",
    "def get_item(x, i):\n",
    "    return x[i]\n",
    "\n",
    "saved_count = 0\n",
    "\n",
    "for i in range(n_img):\n",
    "    img = np.array(images[i])\n",
    "    m   = np.array(masks[i])\n",
    "\n",
    "    uniq = np.unique(m)\n",
    "    non_zero_classes = uniq[uniq > 0]\n",
    "\n",
    "    # we only want masks with EXACTLY ONE non-zero class (one card)\n",
    "    if len(non_zero_classes) != 1:\n",
    "        continue\n",
    "    \n",
    "    mask_to_save = m.astype(np.uint8)\n",
    "    fname = f\"{i:06d}.png\"\n",
    "    Image.fromarray(img).save(os.path.join(IMG_DIR,  fname))\n",
    "    Image.fromarray(mask_to_save).save(os.path.join(MASK_DIR, fname))\n",
    "\n",
    "    saved_count += 1\n",
    "\n",
    "print(f\"Done! Saved {saved_count} single-card samples into '{OUT_ROOT}/images' and '{OUT_ROOT}/masks'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Converted 831 samples into 'single_card_2/train' and 'single_card_2/validation'.\n"
     ]
    }
   ],
   "source": [
    "# we want to:\n",
    "#   1. Turn this into a *binary* problem:\n",
    "#         0 = background\n",
    "#         2 = \"card\" (any card class)\n",
    "#      (So all card labels 1..52 become just 2.)\n",
    "#   2. Split the data into:\n",
    "#         - 60% training set\n",
    "#         - 40% validation set\n",
    "#   3. Save everything into this folder structure:\n",
    "#         single_card_2/\n",
    "#             train/\n",
    "#                 images/\n",
    "#                 masks/\n",
    "#             validation/\n",
    "#                 images/\n",
    "#                 masks/\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Source (multi-class, single-card) dataset\n",
    "SRC_ROOT = \"single_card_52\"\n",
    "SRC_IMG_DIR  = os.path.join(SRC_ROOT, \"images\")\n",
    "SRC_MASK_DIR = os.path.join(SRC_ROOT, \"masks\")\n",
    "\n",
    "# Target (binary card=2) dataset with train/val\n",
    "OUT_ROOT = \"single_card_2\"\n",
    "TRAIN_IMG_DIR = os.path.join(OUT_ROOT, \"train\", \"images\")\n",
    "TRAIN_MASK_DIR = os.path.join(OUT_ROOT, \"train\", \"masks\")\n",
    "VAL_IMG_DIR   = os.path.join(OUT_ROOT, \"validation\", \"images\")\n",
    "VAL_MASK_DIR  = os.path.join(OUT_ROOT, \"validation\", \"masks\")\n",
    "\n",
    "os.makedirs(TRAIN_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(TRAIN_MASK_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(VAL_MASK_DIR, exist_ok=True)\n",
    "\n",
    "mask_files = sorted([f for f in os.listdir(SRC_MASK_DIR) if f.lower().endswith(\".png\")])\n",
    "n = len(mask_files)\n",
    "\n",
    "# 60% train, 40% validation\n",
    "split_idx = int(n * 0.6)\n",
    "\n",
    "converted = 0\n",
    "\n",
    "for k, fname in enumerate(mask_files):\n",
    "    mask_path = os.path.join(SRC_MASK_DIR, fname)\n",
    "    img_path  = os.path.join(SRC_IMG_DIR,  fname)\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    m = Image.open(mask_path)\n",
    "    m_np = np.array(m)\n",
    "\n",
    "    m_np = m_np[..., 0]\n",
    "    m_bin = np.zeros_like(m_np, dtype=np.uint8)\n",
    "    m_bin[m_np > 0] = 2 \n",
    "\n",
    "    if k < split_idx:\n",
    "        out_img_path  = os.path.join(TRAIN_IMG_DIR,  fname)\n",
    "        out_mask_path = os.path.join(TRAIN_MASK_DIR, fname)\n",
    "    else:\n",
    "        out_img_path  = os.path.join(VAL_IMG_DIR,  fname)\n",
    "        out_mask_path = os.path.join(VAL_MASK_DIR, fname)\n",
    "\n",
    "    Image.fromarray(img_np).save(out_img_path)\n",
    "    Image.fromarray(m_bin).save(out_mask_path)\n",
    "\n",
    "    converted += 1\n",
    "\n",
    "print(f\"Done! Converted {converted} samples into '{OUT_ROOT}/train' and '{OUT_ROOT}/validation'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ffb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to COMBINE (merge) these two datasets into one big dataset.\n",
    "#\n",
    "# The final structure will look like:\n",
    "#   merged_dataset/\n",
    "#       train/\n",
    "#           images/\n",
    "#           masks/\n",
    "#       validation/\n",
    "#           images/\n",
    "#           masks/\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "FOOD_ROOT = \"foodseg103_export\"\n",
    "CARD_ROOT = \"single_card_2\"\n",
    "OUT_ROOT  = \"merged_dataset\"\n",
    "\n",
    "# Output folders\n",
    "TRAIN_IMG = os.path.join(OUT_ROOT, \"train\", \"images\")\n",
    "TRAIN_MASK = os.path.join(OUT_ROOT, \"train\", \"masks\")\n",
    "VAL_IMG = os.path.join(OUT_ROOT, \"validation\", \"images\")\n",
    "VAL_MASK = os.path.join(OUT_ROOT, \"validation\", \"masks\")\n",
    "\n",
    "os.makedirs(TRAIN_IMG, exist_ok=True)\n",
    "os.makedirs(TRAIN_MASK, exist_ok=True)\n",
    "os.makedirs(VAL_IMG, exist_ok=True)\n",
    "os.makedirs(VAL_MASK, exist_ok=True)\n",
    "\n",
    "# helper\n",
    "def list_sorted(folder):\n",
    "    return sorted(os.listdir(folder))\n",
    "\n",
    "def copy_pair(src_img, src_mask, dst_img, dst_mask):\n",
    "    shutil.copy2(src_img, dst_img)\n",
    "    shutil.copy2(src_mask, dst_mask)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# MERGE TRAIN SPLITS\n",
    "# -----------------------------------------------------\n",
    "counter = 0\n",
    "print(\"Merging TRAIN...\")\n",
    "\n",
    "# 1. FOOD train\n",
    "food_train_imgs = list_sorted(os.path.join(FOOD_ROOT, \"train\", \"images\"))\n",
    "for name in food_train_imgs:\n",
    "    img_path = os.path.join(FOOD_ROOT, \"train\", \"images\", name)\n",
    "    mask_path = os.path.join(FOOD_ROOT, \"train\", \"masks\", name.replace(\".jpg\", \".png\"))\n",
    "\n",
    "    out_img  = os.path.join(TRAIN_IMG,  f\"{counter:06d}.jpg\")\n",
    "    out_mask = os.path.join(TRAIN_MASK, f\"{counter:06d}.png\")\n",
    "\n",
    "    copy_pair(img_path, mask_path, out_img, out_mask)\n",
    "    counter += 1\n",
    "\n",
    "# 2. CARD train\n",
    "card_train_imgs = list_sorted(os.path.join(CARD_ROOT, \"train\", \"images\"))\n",
    "for name in card_train_imgs:\n",
    "    img_path = os.path.join(CARD_ROOT, \"train\", \"images\", name)\n",
    "    mask_path = os.path.join(CARD_ROOT, \"train\", \"masks\", name)\n",
    "\n",
    "    out_img  = os.path.join(TRAIN_IMG,  f\"{counter:06d}.png\")\n",
    "    out_mask = os.path.join(TRAIN_MASK, f\"{counter:06d}.png\")\n",
    "\n",
    "    copy_pair(img_path, mask_path, out_img, out_mask)\n",
    "    counter += 1\n",
    "\n",
    "print(f\"TRAIN merged: {counter} items\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# MERGE VALIDATION SPLITS\n",
    "# -----------------------------------------------------\n",
    "counter = 0\n",
    "print(\"Merging VALIDATION...\")\n",
    "\n",
    "# 1. FOOD val\n",
    "food_val_imgs = list_sorted(os.path.join(FOOD_ROOT, \"validation\", \"images\"))\n",
    "for name in food_val_imgs:\n",
    "    img_path = os.path.join(FOOD_ROOT, \"validation\", \"images\", name)\n",
    "    mask_path = os.path.join(FOOD_ROOT, \"validation\", \"masks\", name.replace(\".jpg\", \".png\"))\n",
    "\n",
    "    out_img  = os.path.join(VAL_IMG,  f\"{counter:06d}.jpg\")\n",
    "    out_mask = os.path.join(VAL_MASK, f\"{counter:06d}.png\")\n",
    "\n",
    "    copy_pair(img_path, mask_path, out_img, out_mask)\n",
    "    counter += 1\n",
    "\n",
    "# 2. CARD val\n",
    "card_val_imgs = list_sorted(os.path.join(CARD_ROOT, \"validation\", \"images\"))\n",
    "for name in card_val_imgs:\n",
    "    img_path = os.path.join(CARD_ROOT, \"validation\", \"images\", name)\n",
    "    mask_path = os.path.join(CARD_ROOT, \"validation\", \"masks\", name)\n",
    "\n",
    "    out_img  = os.path.join(VAL_IMG,  f\"{counter:06d}.png\")\n",
    "    out_mask = os.path.join(VAL_MASK, f\"{counter:06d}.png\")\n",
    "\n",
    "    copy_pair(img_path, mask_path, out_img, out_mask)\n",
    "    counter += 1\n",
    "\n",
    "print(f\"VALIDATION merged: {counter} items\")\n",
    "\n",
    "print(\"Done! Merged dataset is in merged_dataset/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd58a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5481/5481 [00:40<00:00, 134.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing validation split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2468/2468 [00:06<00:00, 360.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# we want to create YOLO-style LABEL FILES for segmentation (polygons).\n",
    "# where:\n",
    "#   - class_id is in YOLO format:\n",
    "#         0 = food\n",
    "#         1 = card\n",
    "#\n",
    "# Final structure:\n",
    "#   merged_dataset/\n",
    "#       train/\n",
    "#           images/\n",
    "#           masks/\n",
    "#           labels/\n",
    "#       validation/\n",
    "#           images/\n",
    "#           masks/\n",
    "#           labels/\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# New dataset root\n",
    "ROOT = r\"C:\\Users\\siuts\\Downloads\\asm\\CS489\\project\\merged_dataset\"\n",
    "splits = [\"train\", \"validation\"]\n",
    "\n",
    "def mask_to_polygons(mask):\n",
    "    \"\"\"Convert mask (H,W) into class→polygons dict.\"\"\"\n",
    "    polygons = {}\n",
    "    h, w = mask.shape\n",
    "\n",
    "    class_ids = np.unique(mask)\n",
    "    class_ids = class_ids[class_ids != 0]  # remove background (0)\n",
    "\n",
    "    for cid in class_ids:\n",
    "        binary = (mask == cid).astype(np.uint8) * 255\n",
    "\n",
    "        contours, _ = cv2.findContours(\n",
    "            binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "\n",
    "        polygon_list = []\n",
    "        for c in contours:\n",
    "            poly = c.reshape(-1, 2)\n",
    "            px = poly[:, 0] / w\n",
    "            py = poly[:, 1] / h\n",
    "\n",
    "            poly_norm = np.vstack((px, py)).T.reshape(-1).tolist()\n",
    "            polygon_list.append(poly_norm)\n",
    "\n",
    "        if polygon_list:\n",
    "            polygons[cid] = polygon_list\n",
    "\n",
    "    return polygons\n",
    "\n",
    "\n",
    "for split in splits:\n",
    "    mask_dir = os.path.join(ROOT, split, \"masks\")\n",
    "    label_dir = os.path.join(ROOT, split, \"labels\")\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "    mask_files = sorted(os.listdir(mask_dir))\n",
    "    print(f\"Processing {split} split...\")\n",
    "\n",
    "    for fname in tqdm(mask_files):\n",
    "        mask_path = os.path.join(mask_dir, fname)\n",
    "        img_id = os.path.splitext(fname)[0]\n",
    "        label_path = os.path.join(label_dir, f\"{img_id}.txt\")\n",
    "\n",
    "        # load mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        polygons = mask_to_polygons(mask)\n",
    "\n",
    "        with open(label_path, \"w\") as f:\n",
    "            for cid, polys in polygons.items():\n",
    "                # MAP mask class → YOLO class\n",
    "                # mask: 1 = food, 2 = card\n",
    "                # YOLO: 0 = food, 1 = card\n",
    "                if cid == 1:\n",
    "                    yolo_cid = 0\n",
    "                elif cid == 2:\n",
    "                    yolo_cid = 1\n",
    "\n",
    "                for poly in polys:\n",
    "                    line = str(yolo_cid) + \" \" + \" \".join(f\"{p:.6f}\" for p in poly)\n",
    "                    f.write(line + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv422",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
